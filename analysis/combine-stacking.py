#!/usr/bin/env python
'''    
COMBINE STACKING OUTPUT SCRIPT
"Align occupancies of hydrogen bonds to their name accross similar systems or across replicates"

Installation instructions for cedar users:
	1. Copy this file "combine-stacking.py" to your ~/bin dir
	2. Using bash, issue the command: "chmod +x ~/bin/combine-stacking.py"
	3. done 
	
Module load command for Cedar users:
    module load StdEnv/2020 scipy-stack/2022a

How to use:
    1. Fill a dir with stacking.dat files from our other stacking script
    2. Ensure the names of the stacking files are meaningful (system-1.dat, system-2.dat etc.)
    3. Run this script with "combine-stacking.py" (AFTER installing in your ~/bin) 
        3a. Run this script while you are INSIDE the directory with the stacking.dat files 
    4. Take the output .csv file for futher inspection elsewhere
    
Workflow of the script: 
    Import the Acceptor, Donor, and Frac columns from hbond-avg.dat files (there were generated by cpptraj)
    Merge Acceptor and Donor columns into a single field: "hbond"
    Sort "hbond" by string
    Clean, reorder and rename the Frac column to ref the source file(s)
    Combine all additional .dat files into one dataframe by merging on "hbond" and appending "Frac" to an additional column 
    Output a .csv file of the 'final' data frame

Author: Makay Murray 2022
Contact: makay.murray@uleth.ca
Lab: Wetmore @ uLeth
'''

import pandas as pd
import re
import os
import glob
import sys

#%% 
df_final = None # initilize an empty df, this will be filled in the next loop
#%%
#Get all the .dat file names in current path
path = os.getcwd()
dat_files = glob.glob(os.path.join(path, "*.dat"))

if dat_files:
    print("We found", len(dat_files), "dat files!")
else: 
    sys.exit('there are NO .dat files here... Are we in the right directory?')
#%%

# This regex captures anything after stacking-count- and before .dat
interaction_regex = re.compile(r"stacking-count-(.*?).dat") 

all_data = [] # Empty list to hold all data

current_interaction = ""

for f in dat_files:  #with open("stacking-IVT7.dat") as f:
    for line in f:
        line = line.strip() # Strip the line
        if not line: continue # Ig the line is empty, move to the next line

        # If the line begins and ends with arrows, it is a filename so try to extract the interaction from it
        if line.startswith("==>") and line.endswith("<=="):
            inter = interaction_regex.findall(line)
            if not inter: continue                     # if inter is empty, go to the next line
            current_interaction = f"13-vs-{inter[0]}"  # if not, set the currently active interaction

        # If the line doesn't begin and end with arrows, try to extract data from it
        # But only if current_interaction is not empty
        elif current_interaction:                      
            file_row = line.split()        # Split the line on whitespace
            if file_row[1] == "stacked":   
                # If the second element of the row is "stacked", 
                # Create a tuple containing the current_interaction and the number in this line
                df_row = (current_interaction, float(file_row[0])) 
                all_data.append(df_row) # Append the tuple to our list
                
                
df = pd.DataFrame(all_data, columns=["Interaction", f])  # Create a dataframe using the data we read

#%% 
#this is prior code
# loop over the list of dat files
for f in dat_files: 
   
    # Fill the data frame with the first dat file and adjust columns
    if df_final is None:
        df_final = pd.read_csv(f, delim_whitespace=False,  )
        df_final['hbond'] =  df_final["#Acceptor"].astype(str) + str("---") + df_final["Donor"].astype(str)
        df_final = df_final.sort_values(by=['hbond'])
        df_final.pop('#Acceptor')
        df_final.pop('Donor')
        df_final = df_final.reindex(columns=['hbond','Frac'])
    #append the remaining hbond files in the dir into the df_final data frame. 
    df = pd.read_csv(f, delim_whitespace=True, usecols = ['#Acceptor', 'Donor', 'Frac'])
    df['hbond'] =  df["#Acceptor"].astype(str) + str("---") + df["Donor"].astype(str)
    df = df.sort_values(by=['hbond'])
    df.pop('#Acceptor') #delete the #Acceptor column
    df.pop('Donor') #Delete the Donor Column
    df = df.reindex(columns=['hbond','Frac']) #re-order the columns
    df = df.rename(columns = {"Frac":f}) #convert the Frac column header into the file name the data is from. 
    df_final = df_final.merge(df, how='left', on='hbond',) #final merge of the loop to append to the final DF
#%%
df_final.drop(df_final.columns[[1]], axis = 1, inplace = True) #delete the first duplicate FRAC column from the first file
df_final.to_csv('final_hbond.csv', header=True) #save the df to a file

print('The Stacking Data has been combined! Please check final_stacking.csv for your data')
#%%
